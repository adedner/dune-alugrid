Caught DGFException on creation of SGrid, trying default DGF method!

Created parallel ALUGrid<3,3,cube,nonconforming> from macro grid file ''. 

globalRefine: 1
elements = 7282150 (225120,229383,1.01894)   maxLevel = 4   step = 12   time = 0.108   dt = 0.009
elements = 7182778 (222338,227260,1.02214)   maxLevel = 4   step = 23   time = 0.207   dt = 0.009
elements = 7140407 (221163,225303,1.01872)   maxLevel = 4   step = 34   time = 0.306   dt = 0.009
elements = 7329015 (227018,231487,1.01969)   maxLevel = 4   step = 45   time = 0.405   dt = 0.009
elements = 7072801 (219066,222944,1.0177)   maxLevel = 4   step = 56   time = 0.504   dt = 0.009
elements = 7320419 (226756,230735,1.01755)   maxLevel = 4   step = 67   time = 0.603   dt = 0.009
elements = 7195973 (222198,226633,1.01996)   maxLevel = 4   step = 78   time = 0.702   dt = 0.009
elements = 7107640 (219107,224150,1.02302)   maxLevel = 4   step = 89   time = 0.801   dt = 0.009
elements = 7269137 (224868,229141,1.019)   maxLevel = 4   step = 100   time = 0.9   dt = 0.009
elements = 6996774 (215741,220786,1.02338)   maxLevel = 4   step = 112   time = 1.008   dt = 0.009
U2 max: 47.26  min: 36.7
U3 max: 0.02  min: 0
U4 max: 2.41  min: 2.22
U5 max: 13.61  min: 7.21
U6 max: 0.01  min: 0
U7 max: 70.27  min: 59.62
U8 max: 51.78  min: 41.14
Program finished: CPU time = 289.981 sec.
Job  /ncar/opt/lsf/8.3/linux2.6-glibc2.3-x86_64/bin/poejob ./main_ball 3 1 4 none

TID   HOST_NAME   COMMAND_LINE            STATUS            TERMINATION_TIME
===== ========== ================  =======================  ===================
00016 ys0847-ib  ./main_ball 3 1   Done                     05/15/2013 17:33:18
00017 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00018 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00020 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00019 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00021 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00022 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00023 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00024 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00025 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00026 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00027 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00028 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00030 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00029 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00031 ys0847-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00000 ys0601-ib  ./main_ball 3 1   Done                     05/15/2013 17:33:18
00003 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00014 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00015 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00004 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00005 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00006 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00007 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00008 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00009 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00010 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00011 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00012 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00001 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:17
00013 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18
00002 ys0601-ib   ./main_ball 3 1  Done                     05/15/2013 17:33:18

------------------------------------------------------------
Sender: LSF System <lsfadmin@ys0601-ib>
Subject: Job 662845: <mb.32> Done

Job <mb.32> was submitted from host <yslogin1-ib> by user <robertk> in cluster <yellowstone>.
Job was executed on host(s) <16*ys0601-ib>, in queue <small>, as user <robertk> in cluster <yellowstone>.
                            <16*ys0847-ib>
</glade/u/home/robertk> was used as the home directory.
</glade/u/home/robertk/work/Dune/trunk/alugrid/examples> was used as the working directory.
Started at Wed May 15 17:28:20 2013
Results reported at Wed May 15 17:33:22 2013

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF batch script to run an MPI application
#
#BSUB -P P86850055           # project code
#BSUB -W 00:30               # wall-clock time (hrs:mins)
#BSUB -n 32              # number of tasks in job
#BSUB -R span[ptile=16]    # run 16 MPI tasks per node
#BSUB -J mb.32            # job name
#BSUB -o ./out/mb.32.%J.out  # output file name 
#BSUB -e ./err/mb.32.%J.err  # error file name
#BSUB -q small             # queue
#run the executable
mpirun.lsf ./main_ball 3 1 4 none

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time   :   9315.99 sec.
    Max Memory :       150 MB
    Max Swap   :       995 MB

    Max Processes  :         7
    Max Threads    :        17

The output (if any) is above this job summary.



PS:

Read file <./err/mb.32.662845.err> for stderr output of this job.

