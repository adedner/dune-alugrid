Execute poe command line: poe  ./main_ball 4 0 3 none
Caught DGFException on creation of SGrid, trying default DGF method!

Created parallel ALUGrid<3,3,cube,nonconforming> from macro grid file ''. 

globalRefine: 0
elements = 7323331 (28119,29108,1.03517)   maxLevel = 3   step = 12   time = 0.108   dt = 0.009
elements = 7210827 (27684,28616,1.03367)   maxLevel = 3   step = 23   time = 0.207   dt = 0.009
elements = 7161568 (27501,28462,1.03494)   maxLevel = 3   step = 34   time = 0.306   dt = 0.009
elements = 7330513 (28160,29140,1.0348)   maxLevel = 3   step = 45   time = 0.405   dt = 0.009
elements = 7065549 (27097,28027,1.03432)   maxLevel = 3   step = 56   time = 0.504   dt = 0.009
elements = 7317948 (28105,29032,1.03298)   maxLevel = 3   step = 67   time = 0.603   dt = 0.009
elements = 7209966 (27655,28675,1.03688)   maxLevel = 3   step = 78   time = 0.702   dt = 0.009
elements = 7128311 (27359,28348,1.03615)   maxLevel = 3   step = 89   time = 0.801   dt = 0.009
elements = 7309625 (28055,29030,1.03475)   maxLevel = 3   step = 100   time = 0.9   dt = 0.009
elements = 7054069 (27078,28041,1.03556)   maxLevel = 3   step = 112   time = 1.008   dt = 0.009
U2 max: 0.95  min: 0.45
U3 max: 0.02  min: 0
U4 max: 35.22  min: 23
U5 max: 0.84  min: 0.1
U6 max: 27.27  min: 20.52
U7 max: 0.88  min: 0.01
U8 max: 41.1  min: 30.26
Program finished: CPU time = 88.2446 sec.

------------------------------------------------------------
Sender: LSF System <lsfadmin@ys1007-ib>
Subject: Job 920564: <mb.256> in cluster <yellowstone> Done

Job <mb.256> was submitted from host <yslogin3-ib> by user <robertk> in cluster <yellowstone>.
Job was executed on host(s) <16*ys1007-ib>, in queue <small>, as user <robertk> in cluster <yellowstone>.
                            <16*ys1008-ib>
                            <16*ys1259-ib>
                            <16*ys1260-ib>
                            <16*ys2439-ib>
                            <16*ys2440-ib>
                            <16*ys6244-ib>
                            <16*ys6327-ib>
                            <16*ys6328-ib>
                            <16*ys6329-ib>
                            <16*ys6330-ib>
                            <16*ys6331-ib>
                            <16*ys6333-ib>
                            <16*ys6334-ib>
                            <16*ys6335-ib>
                            <16*ys6336-ib>
</glade/u/home/robertk> was used as the home directory.
</glade/u/home/robertk/work/Dune/trunk/alugrid/examples> was used as the working directory.
Started at Wed Feb 19 16:42:18 2014
Results reported at Wed Feb 19 16:44:45 2014

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF batch script to run an MPI application
#
#BSUB -P P86850055           # project code
#BSUB -W 00:30               # wall-clock time (hrs:mins)
#BSUB -n 256              # number of tasks in job
#BSUB -R span[ptile=16]    # run 16 MPI tasks per node
#BSUB -J mb.256            # job name
#BSUB -o ./out/mb.256.%J.out  # output file name 
#BSUB -e ./err/mb.256.%J.err  # error file name
#BSUB -q small             # queue
#run the executable
export MP_CSS_INTERRUPT=yes
export MP_EAGER_LIMIT=4194305
export MP_EAGER_LIMIT_LOCAL=4194305
mpirun.lsf ./main_ball 4 0 3 none

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               30063.00 sec.
    Max Memory :             31285 MB
    Average Memory :         9424.75 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Processes :          276
    Max Threads :            2937

The output (if any) is above this job summary.



PS:

Read file <./err/mb.256.920564.err> for stderr output of this job.

