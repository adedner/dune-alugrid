Caught DGFException on creation of SGrid, trying default DGF method!

Created parallel ALUGrid<3,3,cube,nonconforming> from macro grid file ''. 

globalRefine: 1
elements = 7283207 (224862,229839,1.02213)   maxLevel = 4   step = 12   time = 0.108   dt = 0.009
elements = 7181679 (221852,228229,1.02874)   maxLevel = 4   step = 23   time = 0.207   dt = 0.009
elements = 7139273 (219739,226263,1.02969)   maxLevel = 4   step = 34   time = 0.306   dt = 0.009
elements = 7328280 (225955,231832,1.02601)   maxLevel = 4   step = 45   time = 0.405   dt = 0.009
elements = 7078926 (218283,224970,1.03063)   maxLevel = 4   step = 56   time = 0.504   dt = 0.009
elements = 7309940 (224708,232310,1.03383)   maxLevel = 4   step = 67   time = 0.603   dt = 0.009
elements = 7205297 (222199,228932,1.0303)   maxLevel = 4   step = 78   time = 0.702   dt = 0.009
elements = 7102761 (218355,225598,1.03317)   maxLevel = 4   step = 89   time = 0.801   dt = 0.009
elements = 7269991 (224370,230600,1.02777)   maxLevel = 4   step = 100   time = 0.9   dt = 0.009
elements = 6998580 (216144,221593,1.02521)   maxLevel = 4   step = 112   time = 1.008   dt = 0.009
U2 max: 0.05  min: 0.03
U3 max: 0.02  min: 0
U4 max: 67.2  min: 28.03
U5 max: 14.44  min: 7.79
U6 max: 0.01  min: 0
U7 max: 81.41  min: 42.39
U8 max: 69.63  min: 30.17
Program finished: CPU time = 305.662 sec.
Job  /ncar/opt/lsf/8.3/linux2.6-glibc2.3-x86_64/bin/poejob ./main_ball 3 1 4 none

TID   HOST_NAME   COMMAND_LINE            STATUS            TERMINATION_TIME
===== ========== ================  =======================  ===================
00016 ys1641-ib  ./main_ball 3 1   Done                     05/15/2013 15:49:29
00017 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00018 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00020 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00019 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00021 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00022 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00023 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00024 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00025 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00026 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00027 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00028 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00030 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00029 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00031 ys1641-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00000 ys1322-ib  ./main_ball 3 1   Done                     05/15/2013 15:49:29
00002 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00014 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00003 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00015 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00004 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00005 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00006 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00007 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00008 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00009 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00010 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00011 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00012 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00001 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29
00013 ys1322-ib   ./main_ball 3 1  Done                     05/15/2013 15:49:29

------------------------------------------------------------
Sender: LSF System <lsfadmin@ys1322-ib>
Subject: Job 662277: <mb.32> Done

Job <mb.32> was submitted from host <yslogin3-ib> by user <robertk> in cluster <yellowstone>.
Job was executed on host(s) <16*ys1322-ib>, in queue <small>, as user <robertk> in cluster <yellowstone>.
                            <16*ys1641-ib>
</glade/u/home/robertk> was used as the home directory.
</glade/u/home/robertk/work/Dune/trunk/alugrid/examples> was used as the working directory.
Started at Wed May 15 15:44:14 2013
Results reported at Wed May 15 15:49:33 2013

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF batch script to run an MPI application
#
#BSUB -P P86850055           # project code
#BSUB -W 00:10               # wall-clock time (hrs:mins)
#BSUB -n 32              # number of tasks in job
#BSUB -R span[ptile=16]    # run 16 MPI tasks per node
#BSUB -J mb.32            # job name
#BSUB -o ./out/mb.32.%J.out  # output file name 
#BSUB -e ./err/mb.32.%J.err  # error file name
#BSUB -q small             # queue
#run the executable
mpirun.lsf ./main_ball 3 1 4 none

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time   :   9841.33 sec.
    Max Memory :      7744 MB
    Max Swap   :     18580 MB

    Max Processes  :        23
    Max Threads    :       209

The output (if any) is above this job summary.



PS:

Read file <./err/mb.32.662277.err> for stderr output of this job.

