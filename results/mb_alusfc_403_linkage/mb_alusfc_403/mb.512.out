Execute poe command line: poe  ./main_ball 4 0 3 none
Caught DGFException on creation of SGrid, trying default DGF method!

Created parallel ALUGrid<3,3,cube,nonconforming> from macro grid file ''. 

globalRefine: 0
elements = 7325564 (13817,14799,1.07107)   maxLevel = 3   step = 12   time = 0.108   dt = 0.009
elements = 7210981 (13576,14572,1.07336)   maxLevel = 3   step = 23   time = 0.207   dt = 0.009
elements = 7162604 (13545,14484,1.06932)   maxLevel = 3   step = 34   time = 0.306   dt = 0.009
elements = 7334419 (13818,14827,1.07302)   maxLevel = 3   step = 45   time = 0.405   dt = 0.009
elements = 7064583 (13296,14287,1.07453)   maxLevel = 3   step = 56   time = 0.504   dt = 0.009
elements = 7319831 (13792,14778,1.07149)   maxLevel = 3   step = 67   time = 0.603   dt = 0.009
elements = 7213732 (13654,14549,1.06555)   maxLevel = 3   step = 78   time = 0.702   dt = 0.009
elements = 7125301 (13448,14408,1.07139)   maxLevel = 3   step = 89   time = 0.801   dt = 0.009
elements = 7310682 (13789,14773,1.07136)   maxLevel = 3   step = 100   time = 0.9   dt = 0.009
elements = 7053824 (13282,14231,1.07145)   maxLevel = 3   step = 112   time = 1.008   dt = 0.009
U2 max: 0.73  min: 0.45
U3 max: 0.03  min: 0
U4 max: 20.71  min: 12.71
U5 max: 0.5  min: 0.02
U6 max: 19.46  min: 12.78
U7 max: 0.73  min: 0
U8 max: 26.02  min: 17.3
Program finished: CPU time = 58.7061 sec.

------------------------------------------------------------
Sender: LSF System <lsfadmin@ys1371-ib>
Subject: Job 927776: <mb.512> in cluster <yellowstone> Done

Job <mb.512> was submitted from host <yslogin3-ib> by user <robertk> in cluster <yellowstone>.
Job was executed on host(s) <16*ys1371-ib>, in queue <small>, as user <robertk> in cluster <yellowstone>.
                            <16*ys1413-ib>
                            <16*ys1420-ib>
                            <16*ys1421-ib>
                            <16*ys1422-ib>
                            <16*ys1450-ib>
                            <16*ys1451-ib>
                            <16*ys1452-ib>
                            <16*ys1453-ib>
                            <16*ys1454-ib>
                            <16*ys1455-ib>
                            <16*ys1456-ib>
                            <16*ys1457-ib>
                            <16*ys1458-ib>
                            <16*ys1459-ib>
                            <16*ys1460-ib>
                            <16*ys1461-ib>
                            <16*ys1462-ib>
                            <16*ys1463-ib>
                            <16*ys1464-ib>
                            <16*ys1465-ib>
                            <16*ys1466-ib>
                            <16*ys1467-ib>
                            <16*ys1468-ib>
                            <16*ys1469-ib>
                            <16*ys1470-ib>
                            <16*ys1502-ib>
                            <16*ys1503-ib>
                            <16*ys1504-ib>
                            <16*ys1505-ib>
                            <16*ys1506-ib>
                            <16*ys1507-ib>
</glade/u/home/robertk> was used as the home directory.
</glade/u/home/robertk/work/Dune/trunk/alugrid/examples/run/mb_alusfc_403> was used as the working directory.
Started at Thu Feb 20 20:14:30 2014
Results reported at Thu Feb 20 20:16:21 2014

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# LSF batch script to run an MPI application
#
#BSUB -P P86850055           # project code
#BSUB -W 00:30               # wall-clock time (hrs:mins)
#BSUB -n 512              # number of tasks in job
#BSUB -R span[ptile=16]    # run 16 MPI tasks per node
#BSUB -J mb.512            # job name
#BSUB -o ./mb.512.out  # output file name 
#BSUB -e ./mb.512.err  # error file name
#BSUB -q small             # queue
#run the executable
export MP_CSS_INTERRUPT=yes
export MP_EAGER_LIMIT=4194305
export MP_EAGER_LIMIT_LOCAL=4194305
mpirun.lsf ./main_ball 4 0 3 none

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :               39877.00 sec.
    Max Memory :             52110 MB
    Average Memory :         1923.00 MB
    Total Requested Memory : -
    Delta Memory :           -
    (Delta: the difference between total requested memory and actual max usage.)
    Max Processes :          157
    Max Threads :            1702

The output (if any) is above this job summary.



PS:

Read file <./mb.512.err> for stderr output of this job.

