/** include config file generated by configure
 *  (i.e., know what grids are present, etc)
 *  this should always be included first */
#include <config.h>
/** standard headers **/
#include <iostream>
/** dune (mpi, field-vector and grid type for dgf) **/
#include <dune/common/mpihelper.hh>     
#include <dune/common/fvector.hh>        
#include <dune/common/timer.hh>      
/** Zoltan **/
//#include <mpi.h>
//#include <stdio.h>
//#include <stdlib.h>
//#include <ctype.h>
#include "zoltan.h"

#include "zoltaninterface.hh"
//#include "simplePHG.hh"
//#include "simplePHGtwoGIDs.hh"

typedef Dune::GridSelector::GridType Grid;

/** numerical scheme **/
#include "../piecewisefunction.hh"

/** adaptation scheme **/
#include "adaptation.hh"

struct AssignRank
{
  AssignRank(const int rank) : rank_(rank) {}
  Dune::FieldVector<double,2> 
    initial(const Dune::FieldVector<double,Grid::dimensionworld> &) const
  {
    return Dune::FieldVector<double,2>(rank_);
  }
  private:
  int rank_;
};


// method
// ------
void method ( int startLevel, int maxLevel, const char* outpath )
{
  int myRank, numProcs;
  MPI_Comm_rank(MPI_COMM_WORLD, &myRank); //MJ
  MPI_Comm_size(MPI_COMM_WORLD, &numProcs); //MJ

  /* Grid construction ... */
  std::string name = "./unitcube3d.dgf" ;
  // create grid pointer and release to free memory of GridPtr
  Grid* gridPtr = Dune::GridPtr<Grid>(name).release() ;

  Grid &grid = *gridPtr;

  //LoadBalanceHandle<Grid> ldb(grid);
  typedef Dune::LoadBalanceHandleIF< LoadBalanceHandle<Grid> > DataHandleInterface;
  // grid.loadBalance( (DataHandleInterface&)(ldb) );
  grid.loadBalance();

  const bool verboseRank = grid.comm().rank() == 0 ;

  std::string outPath( outpath );
  const bool writeOutput = ( outPath != "none" ) ;

  /* ... some global refinement steps */
  if( verboseRank ) 
    std::cout << "globalRefine: " << startLevel << std::endl;
  grid.globalRefine( startLevel );

  /* get view to leaf grid */
  typedef Grid::Partition< Dune::Interior_Partition >::LeafGridView GridView;
  GridView gridView = grid.leafView< Dune::Interior_Partition >();

  /* construct data vector for solution */
  typedef PiecewiseFunction< GridView, Dune::FieldVector< double, 2 > > DataType;
  DataType solution( gridView );
  solution.initialize( AssignRank(grid.comm().rank()) );

  /* create VTK writer for data sequqnce */
  Dune::VTKSequenceWriter< GridView > vtkOut( gridView, "solution", outPath, ".", Dune::VTK::nonconforming );
  if( writeOutput ) 
  {
    VTKData< DataType >::addTo( solution, vtkOut );
    VTKData< DataType >::addPartitioningData( grid.comm().rank(), vtkOut );
  }



  /// Start MJ
  /******************************************************************
  ** Create a Zoltan library structure for this instance of load
  ** balancing.  Set the parameters and query functions that will
  ** govern the library's calculation.  See the Zoltan User's
  ** Guide for the definition of these and many other parameters.
  ******************************************************************/

  int rc;
  int changes, numGidEntries, numLidEntries, numImport, numExport;
  ZOLTAN_ID_PTR importGlobalGids, importLocalGids, exportGlobalGids, exportLocalGids;
  int *importProcs, *importToPart, *exportProcs, *exportToPart;


  float ver;
  int argc_zoltan = 1;
  char *argv_zoltan[1] = {"./dune_lbtest"};
  rc = Zoltan_Initialize(argc_zoltan, argv_zoltan, &ver);

  if (rc != ZOLTAN_OK){
    printf("sorry...\n");
    MPI_Finalize();
    exit(0);
  }


  /* create Zoltan Hypergraph here */
  HGRAPH_DATA hg;
  int NUM_GID_ENTRIES = 4;
  write_hypergraph(myRank, numProcs, grid, &hg, NUM_GID_ENTRIES);
  //read_input_file(myRank, numProcs, "hypergraph.txt", &hg);

cout << "hypergraph wurde geschrieben" << endl;

  struct Zoltan_Struct *zz;
  zz = Zoltan_Create(MPI_COMM_WORLD);

  // General parameters

  Zoltan_Set_Param(zz, "DEBUG_LEVEL", "0");
  Zoltan_Set_Param(zz, "LB_METHOD", "HYPERGRAPH");   /* partitioning method */
  Zoltan_Set_Param(zz, "HYPERGRAPH_PACKAGE", "PHG"); /* version of method */
  //Zoltan_Set_Param(zz, "NUM_GID_ENTRIES", "2");/* global IDs are integers */
  Zoltan_Set_Param(zz, "NUM_GID_ENTRIES", "4");/* global IDs are integers */
  //Zoltan_Set_Param(zz, "NUM_GID_ENTRIES", "1");/* global IDs are integers */
  Zoltan_Set_Param(zz, "NUM_LID_ENTRIES", "1");/* local IDs are integers */
  Zoltan_Set_Param(zz, "RETURN_LISTS", "ALL"); /* export AND import lists */
  Zoltan_Set_Param(zz, "OBJ_WEIGHT_DIM", "0"); /* use Zoltan default vertex weights */
  Zoltan_Set_Param(zz, "EDGE_WEIGHT_DIM", "0");/* use Zoltan default hyperedge weights */

  /* PHG parameters  - see the Zoltan User's Guide for many more
   *   (The "REPARTITION" approach asks Zoltan to create a partitioning that is
   *    better but is not too far from the current partitioning, rather than partitioning 
   *    from scratch.  It may be faster but of lower quality that LB_APPROACH=PARTITION.)
  */

  Zoltan_Set_Param(zz, "LB_APPROACH", "REPARTITION");


  /* Application defined query functions */

  Zoltan_Set_Num_Obj_Fn(zz, get_number_of_vertices, &hg);
  Zoltan_Set_Obj_List_Fn(zz, get_vertex_list, &hg);
  Zoltan_Set_HG_Size_CS_Fn(zz, get_hypergraph_size, &hg);
  Zoltan_Set_HG_CS_Fn(zz, get_hypergraph, &hg);

  /* Register fixed object callback functions */
  if (Zoltan_Set_Fn(zz, ZOLTAN_NUM_FIXED_OBJ_FN_TYPE,
        (void (*)()) get_num_fixed_obj,
        (void *) &hg) == ZOLTAN_FATAL) {
    return;
  }

  if (Zoltan_Set_Fn(zz, ZOLTAN_FIXED_OBJ_LIST_FN_TYPE,
        (void (*)()) get_fixed_obj_list,
        (void *) &hg) == ZOLTAN_FATAL) {
    return;
  }

  /******************************************************************
  ** Zoltan can now partition the vertices of hypergraph.
  ** In this simple example, we assume the number of partitions is
  ** equal to the number of processes.  Process rank 0 will own
  ** partition 0, process rank 1 will own partition 1, and so on.
  ******************************************************************/

  rc = Zoltan_LB_Partition(zz, // input (all remaining fields are output)
        &changes,        // 1 if partitioning was changed, 0 otherwise 
        &numGidEntries,  // Number of integers used for a global ID 
        &numLidEntries,  // Number of integers used for a local ID 
        &numImport,      // Number of vertices to be sent to me 
        &importGlobalGids,  // Global IDs of vertices to be sent to me 
        &importLocalGids,   // Local IDs of vertices to be sent to me 
        &importProcs,    // Process rank for source of each incoming vertex 
        &importToPart,   // New partition for each incoming vertex 
        &numExport,      // Number of vertices I must send to other processes
        &exportGlobalGids,  // Global IDs of the vertices I must send 
        &exportLocalGids,   // Local IDs of the vertices I must send 
        &exportProcs,    // Process to which I send each of the vertices 
        &exportToPart);  // Partition to which each vertex will belong 

cout << "the zoltan partitioning is done" << endl;
cout << "Process " << myRank << " has to export " << numExport << " elements" << endl;

  ZOLTAN_PARTITIONING new_partitioning;
  new_partitioning.changes = changes; // 1 if partitioning was changed, 0 otherwise 
  new_partitioning.numGidEntries = numGidEntries;  // Number of integers used for a global ID 
  new_partitioning.numExport = numExport;  // Number of vertices I must send to other processes
  new_partitioning.exportGlobalGids = exportGlobalGids;  // Global IDs of the vertices I must send 
  new_partitioning.exportProcs = exportProcs;    // Process to which I send each of the vertices

  Zoltan_Destroy(&zz);
  if (rc != ZOLTAN_OK){
    printf("sorry...\n");
    MPI_Finalize();
    Zoltan_Destroy(&zz);
    exit(0);
  }

  /******************************************************************
  ** Now all the information we need is written in exportGlobalGids:
  ** All that is left to do is access this information from the 
  ** adaptation method and tell each element to which process it 
  ** belongs. 
  ******************************************************************/

  /// End MJ



  /* create adaptation method */
  typedef LeafAdaptation< Grid > AdaptationType;
  AdaptationType adaptation( grid, new_partitioning );

  if( writeOutput ) 
  {
    /* output the initial grid and the solution */
    vtkOut.write( 0.0 );
  }

  /* final time for simulation */
  const double endTime = 1.;
  /* interval for saving data */
  const double saveInterval = 0.2;
  /* first point where data is saved */
  double saveStep = saveInterval;

  /* now do the time stepping */
  unsigned int step = 0;
  double time = 0.0;
  while ( time < endTime ) 
  {
    double dt = saveInterval;

    /* augment time */
    time += dt;
    ++step;

    /* check if data should be written */
    if( time >= saveStep )
    {
      if( writeOutput ) 
      {
        /* visualize with VTK */
        vtkOut.write( time );
      }
      /* set saveStep for next save point */
      saveStep += saveInterval;
    }

cout << "I am now going to apply the new Zoltan partitioning" << endl;
    adaptation( solution );

  }           

  if( writeOutput ) 
  {
    /* output final result */
    vtkOut.write( time );
  }

  // delete grid 
  delete gridPtr ;
}
/***************************************************
 ** main program with parameters:                 **
 ** 1) number of problem to use (initial data...) **
 ** 2) number of global refinement steps          **
 ** 3) maximal level to use during refinement     **
 ***************************************************/
int main ( int argc , char **argv )
try
{

  /* initialize MPI, finalize is done automatically on exit */
  Dune::MPIHelper &mpi = Dune::MPIHelper::instance( argc, argv );

  
  if( argc < 2 )
  {
    /* display usage */
    if( mpi.rank() == 0 )
      std::cout << "Usage: " << argv[ 0 ] << " [startLevel] [maxLevel]" << std::endl;
    return 0;
  }

  /* get level to use for computationa */
  const int startLevel = (argc > 1 ? atoi( argv[ 1 ] ) : 0);
  const int maxLevel = (argc > 2 ? atoi( argv[ 2 ] ) : startLevel);

  const char* path = (argc > 3) ? argv[ 3 ] : "./";
  method( startLevel, maxLevel, path );

  /* done */
  return 0;
}
catch( const std::exception &e )
{
  std::cout << "STL ERROR: " << e.what() << std::endl;
  return 1;
}
catch( const Dune::Exception &e )
{
  std::cout << "DUNE ERROR: " << e << std::endl;
  return 1;
}
catch( ... )
{
  std::cout << "Unknown ERROR" << std::endl;
  return 1;
}
