/** include config file generated by configure
 *  (i.e., know what grids are present, etc)
 *  this should always be included first */
#include <config.h>
/** standard headers **/
#include <iostream>
/** dune (mpi, field-vector and grid type for dgf) **/
#include <dune/common/mpihelper.hh>     
#include <dune/common/fvector.hh>        
#include <dune/common/timer.hh>        

#include "../piecewisefunction.hh"
#include "loadbalance.hh"
#include "writedgf.hh"

template <class Grid>
struct AssignRank
{
  AssignRank(const int rank) : rank_(rank) {}
  Dune::FieldVector<double,2> 
    initial(const Dune::FieldVector<double,Grid::dimensionworld> &) const
  {
    return Dune::FieldVector<double,2>(rank_);
  }
  private:
  int rank_;
};
// method
// ------
void partition ( const std::string name, int level )
{
  typedef Dune::GridSelector::GridType Grid;
  /* Grid construction ... */
  // create grid pointer and release to free memory of GridPtr
  Dune::GridPtr< Grid > gridPtr( name );

  Grid &grid = *gridPtr;

  typedef Grid::LeafGridView GridView;
  typedef GridView::IndexSet IndexSetType;
  GridView gridView = grid.leafView();
  const IndexSetType &indexSet = gridView.indexSet();
  size_t nofElParams = gridPtr.nofParameters( 0 );
  std::vector< double > eldat( 0 );

  if( nofElParams > 0 )
  {
    std::cout << "Reading Element Parameters:" << std::endl;
    eldat.resize( indexSet.size(0) * nofElParams );
    const Dune::PartitionIteratorType partType = Dune::All_Partition;
    typedef GridView::Codim< 0 >::Partition< partType >::Iterator Iterator;
    const Iterator enditer = gridView.end< 0, partType >();
    for( Iterator iter = gridView.begin< 0, partType >(); iter != enditer; ++iter )
    {
      const std::vector< double > &param = gridPtr.parameters( *iter );
      assert( param.size() == nofElParams );
      for( size_t i = 0; i < nofElParams; ++i )
      {
        eldat[ indexSet.index(*iter) * nofElParams + i ] = param[ i ];
      }
    }
  }

#if HAVE_ZOLTAN && USE_ZOLTANLB
  typedef ZoltanLoadBalanceHandle<Grid> LoadBalancer;
#else
  typedef SimpleLoadBalanceHandle<Grid> LoadBalancer;
#endif

  LoadBalancer ldb(grid);
  ldb.repartition();
  if (grid.comm().rank() == 0)
  {
    DGFWriter<GridView> writer(grid.leafView());
    for (int q=0;q<grid.comm().size();q++)
      writer.write(name,ldb,q);
  }
}

void method ( const std::string name, const char *outpath )
{
  typedef Dune::GridSelector::GridType Grid;
  /* Grid construction ... */
  // create grid pointer and release to free memory of GridPtr
  Grid* gridPtr = Dune::GridPtr<Grid>(name).release() ;

  Grid &grid = *gridPtr;

  std::string outPath( outpath );
  const bool writeOutput = ( outPath != "none" ) ;
  if (!writeOutput)
    return;

  /* get view to leaf grid */
  typedef Grid::Partition< Dune::Interior_Partition >::LeafGridView GridView;
  GridView gridView = grid.leafView< Dune::Interior_Partition >();

  /* construct data vector for solution */
  typedef PiecewiseFunction< GridView, Dune::FieldVector< double, 2 > > DataType;
  DataType solution( gridView );
  solution.initialize( AssignRank<Grid>(grid.comm().rank()) );

  /* create VTK writer for data sequqnce */
  Dune::VTKSequenceWriter< GridView > vtkOut( gridView, "solution", outPath, ".", Dune::VTK::nonconforming );
  VTKData< DataType >::addTo( solution, vtkOut );
  VTKData< DataType >::addPartitioningData( grid.comm().rank(), vtkOut );
  vtkOut.write( 0.0 );
}
/***************************************************
 ** main program with parameters:                 **
 ** 1) number of problem to use (initial data...) **
 ** 2) number of global refinement steps          **
 ** 3) maximal level to use during refinement     **
 ***************************************************/
int main ( int argc , char **argv )
try
{
  /* initialize MPI, finalize is done automatically on exit */
  Dune::MPIHelper &mpi = Dune::MPIHelper::instance( argc, argv );
  
#if HAVE_ZOLTAN 
  float version;
  int rc = Zoltan_Initialize(argc, argv, &version);
  if (rc != ZOLTAN_OK){
    printf("sorry zoltan did not initialize successfully...\n");
    MPI_Finalize();
    exit(0);
  }
#endif

  if( argc < 2 )
  {
    /* display usage */
    if( mpi.rank() == 0 )
      std::cout << "Usage: " << argv[ 0 ] << " [dgf file] [Level]" << std::endl;
    return 0;
  }

  /* get level to use for computationa */
  const char* filename = argv[ 1 ];
  const int level = (argc > 2 ? atoi( argv[ 1 ] ) : 0);
  const char* path = (argc > 3) ? argv[ 3 ] : "./";

  partition( filename, level );

  mpi.getCollectiveCommunication().barrier();

  std::stringstream newName;
  newName << filename << "." << mpi.rank();
  method( newName.str(), path );

  /* done */
  return 0;
}
catch( const std::exception &e )
{
  std::cout << "STL ERROR: " << e.what() << std::endl;
  return 1;
}
catch( const Dune::Exception &e )
{
  std::cout << "DUNE ERROR: " << e << std::endl;
  return 1;
}
catch( ... )
{
  std::cout << "Unknown ERROR" << std::endl;
  return 1;
}
